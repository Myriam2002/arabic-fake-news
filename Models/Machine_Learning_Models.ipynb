{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\dell\\anaconda3\\lib\\site-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.5.1)\n",
            "Requirement already satisfied: nltk in c:\\users\\dell\\anaconda3\\lib\\site-packages (3.6)\n",
            "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: click in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: regex in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\dell\\anaconda3\\lib\\site-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas scikit-learn nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in c:\\users\\dell\\anaconda3\\lib\\site-packages (2.1.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\dell\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: scipy in c:\\users\\dell\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pKEMtvrcEyYA"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn import svm\n",
        "import xgboost as xgb\n",
        "\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing of the combined dataset.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5096, 50)\n",
            "(1274, 50)\n",
            "(5096,)\n",
            "(1274,)\n"
          ]
        }
      ],
      "source": [
        "# Download necessary NLTK data\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Arabic stopwords\n",
        "arabic_stop_words = set(stopwords.words('arabic'))\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('compiled_real_fake_news_dataset.csv')\n",
        "\n",
        "# Step 1: Text Preprocessing for Arabic\n",
        "def preprocess_text_arabic(text):\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    # Remove non-Arabic characters and digits\n",
        "    text = re.sub(r'[^\\u0600-\\u06FF\\s]', '', text)\n",
        "\n",
        "    # Normalize text\n",
        "    text = re.sub(r'[إأآا]', 'ا', text)\n",
        "    text = re.sub(r'ة', 'ه', text)\n",
        "    text = re.sub(r'ى', 'ي', text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    text = ' '.join([word for word in text.split() if word not in arabic_stop_words])\n",
        "\n",
        "    return text\n",
        "\n",
        "# Apply the preprocessing function to the 'text' column\n",
        "df['clean_text'] = df['text'].apply(preprocess_text_arabic)\n",
        "\n",
        "# Step 2: Encode the labels (real/fake)\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'])  # Assuming 'label' column has 'real' and 'fake' values\n",
        "\n",
        "# Step 3: Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train_texts, X_test_texts, y_train, y_test = train_test_split(df['clean_text'], y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Fit the TF-IDF vectorizer on the training data only, then transform both sets\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=50)\n",
        "X_train = tfidf_vectorizer.fit_transform(X_train_texts)\n",
        "X_test = tfidf_vectorizer.transform(X_test_texts)\n",
        "\n",
        "# Check the shapes\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SVM\n",
        "Support Vector Machine (SVM) is a supervised machine learning technique commonly applied to classification problems, like fake news detection. In this context, SVM works by separating real and fake news articles using a decision boundary based on the features extracted from Arabic text data. For instance, these features might include word frequencies, linguistic patterns, or even word embeddings tailored for Arabic, which capture contextual relationships in the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-Validation Scores: [0.96764706 0.95976447 0.9656526  0.96074583 0.96467125]\n",
            "Mean Accuracy: 0.9637 ± 0.0030\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Train the SVM classifier\n",
        "svm_classifier = svm.SVC(kernel='linear', random_state=42)\n",
        "\n",
        "# Perform cross-validation to confirm that the number of tfidf features was enough by checking consistency of accuracy among folds\n",
        "cv_scores = cross_val_score(svm_classifier, X_train, y_train, cv=5) \n",
        "\n",
        "# Print cross-validation results\n",
        "print(f'Cross-Validation Scores: {cv_scores}')\n",
        "print(f'Mean Accuracy: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Results:\n",
            "Accuracy: 0.9560\n",
            "Precision: 0.9643\n",
            "Recall: 0.9530\n",
            "F1 Score: 0.9586\n"
          ]
        }
      ],
      "source": [
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation results\n",
        "print(\"SVM Results:\")\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### XGBOOST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:52:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost Results:\n",
            "Accuracy: 0.9757\n",
            "Precision: 0.9924\n",
            "Recall: 0.9618\n",
            "F1 Score: 0.9769\n"
          ]
        }
      ],
      "source": [
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 1: Initialize the XGBoost classifier\n",
        "xgb_classifier = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "\n",
        "# Step 2: Train the classifier\n",
        "xgb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Step 3: Predict on the test set\n",
        "y_pred_xgb = xgb_classifier.predict(X_test)\n",
        "\n",
        "# Step 4: Evaluate the model\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "precision_xgb = precision_score(y_test, y_pred_xgb)\n",
        "recall_xgb = recall_score(y_test, y_pred_xgb)\n",
        "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
        "\n",
        "# Step 5: Print the evaluation results for XGBoost\n",
        "print(\"XGBoost Results:\")\n",
        "print(f'Accuracy: {accuracy_xgb:.4f}')\n",
        "print(f'Precision: {precision_xgb:.4f}')\n",
        "print(f'Recall: {recall_xgb:.4f}')\n",
        "print(f'F1 Score: {f1_xgb:.4f}')\n",
        "\n",
        "# Comparison with SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
